import 'dart:convert';

import 'package:copper_app/services/authentication/authentication_service.dart';
import 'package:copper_app/services/design_analysis/models/analysis_response.dart';
import 'package:copper_app/services/design_analysis/models/prompt_content.dart';
import 'package:copper_app/services/kicad_parser/kicad_pcb_design.dart';
import 'package:flutter/rendering.dart';
import 'package:http/http.dart';

/// A service that builds and sends prompts to the Azure OpenAI Service LLM for analyzing PCB designs.
///
/// At a high level, the workflow for this application consists of three major parts:
///
/// 1. The user provides a PCB design file which the app parses.
/// 2. The app generates a prompt based on the parsed PCB design file and questions/requests from the user.
/// 3. The app sends the prompt to an Azure OpenAI Service LLM and displays the response to the user.
///
/// This service is responsible for the second and third steps, generating a prompt based on the parsed PCB design file
/// and questions/requests from the user and then sending the prompt to the LLM for analysis.
///
/// The prompt is generated by combining information from the parsed PCB design file and the user's questions/requests.
/// The parsed PCB design information is used to create content to be sent to the LLM system so it can understand the
/// current state of the PCB design. The user's questions/requests are sent alongside this content and the LLM will
/// generate a response based on the prompt.
///
/// After building the prompt, the service sends it to the Azure OpenAI Service LLM for analysis and receives a
/// response.
class DesignAnalysisService {
  /// Builds and sends a prompt to an Azure OpenAI Service LLM for analyzing a PCB design, and returns the analysis
  /// response.
  Future<AnalysisResponse> analyzePCBDesign({
    required KiCadPCBDesign pcbDesign,
    required String userQuery,
  }) async {
    // Generate a prompt to be sent to the LLM.
    final PromptContent promptContent = _generatePrompt(
      pcbDesign: pcbDesign,
      userQuery: userQuery,
    );

    // Send the prompt to the Azure OpenAI Service LLM for analysis.
    final String analysisResponseData = await _sendPromptToLLM(promptContent);

    // Create an instance of AnalysisResponse from the response.
    final AnalysisResponse analysisResponse = AnalysisResponse(
      prompt: userQuery,
      responseData: analysisResponseData,
    );

    return analysisResponse;
  }

  /// Builds a prompt to be sent to an Azure OpenAI Service LLM.
  ///
  /// The prompt is generated by combining information from the parsed PCB design file and the user's
  /// questions/requests. The project is represented by an instance of the [PromptContent] class.
  PromptContent _generatePrompt({
    required KiCadPCBDesign pcbDesign,
    required String userQuery,
  }) {
    // Create a prompt from the provided information.
    final PromptContent promptContent = PromptContent.fromKiCadPCBDesign(
      pcbDesign: pcbDesign,
      userQuery: userQuery,
    );

    return promptContent;
  }

  /// Sends a prompt to an Azure OpenAI Service LLM for analysis and returns the response.
  Future<String> _sendPromptToLLM(PromptContent promptContent) async {
    // Send the prompt to the Azure OpenAI Service LLM.
    try {
      // Get a Bearer token from the authenticated session.
      final String? bearerToken = AuthenticationService.cachedToken?.rawIdToken;

      // If there is no token, throw an error.
      if (bearerToken == null) {
        throw Exception('No bearer token available for sending prompt to LLM.');
      }

      // Get the prompt content as a string.
      final String promptContentString = promptContent.toString();

      final Response response = await post(
        Uri.parse('https://copperapp.azurewebsites.net/generatecompletion'),
        headers: <String, String>{
          'Content-Type': 'application/json',
          'Authorization': 'Bearer $bearerToken',
        },
        body: json.encode({
          'prompt': promptContentString,
        }),
      );

      // Check if the response is successful.
      if (response.statusCode == 200) {
        return response.body;
      } else {
        throw Exception('Failed to send prompt to LLM with status code, ${response.statusCode}');
      }
    } catch (e) {
      debugPrint('LLM request failed with exception, $e');

      rethrow;
    }
  }
}
